{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn_evaluation import plot\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the text file, ignoring the first line\n",
    "\n",
    "filename=\"./data/MiniBooNE_PID.txt\"\n",
    "data=pd.read_csv(filename,delim_whitespace=True,skiprows=1,header=None)\n",
    "print(data.head(1))\n",
    "X=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create target vector for each row of the dataset. \n",
    "The first value in the first row contains the number of signal events, the second the number of background events. \n",
    "The target vector should contain 1 for signal events and 0 for background events.\"\"\"\n",
    "\n",
    "# Get number of signal and background events\n",
    "signal, background = open(filename).readline().split()\n",
    "\n",
    "y = np.concatenate((np.ones(int(signal)), np.zeros(int(background))))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save the scaled matrix and the target vector as npy files \"\"\"\n",
    "np.save('X.npy', X_scaled)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('X.npy') # load the scaled matrix\n",
    "y=np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vanilla neural network classifier and train it on the training data\n",
    "nn_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter space to search over for the vanilla neural network classifier\n",
    "nn_param_grid = {\n",
    "    'hidden_layer_sizes': [(40,40)],\n",
    "    'activation': [\"logistic\", \"tanh\", \"identity\"],\n",
    "    # 'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [500],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Set up the grid search using 5-fold cross-validation\n",
    "nn_grid_search = GridSearchCV(nn_clf, nn_param_grid, cv=5, scoring='accuracy',verbose=10)\n",
    "# nn_grid_search = RandomizedSearchCV(nn_clf, nn_param_grid, cv=5, scoring='accuracy', n_iter=2)\n",
    "\n",
    "# Perform the grid search on the training set\n",
    "nn_start_time = time.time()\n",
    "nn_grid_search.fit(X_train, y_train)\n",
    "nn_end_time = time.time()\n",
    "print('Time required to grid search Vanilla Neural Network classifier:', nn_end_time - nn_start_time)\n",
    "\n",
    "print('Vanilla Neural Network best hyperparameters:', nn_grid_search.best_params_)\n",
    "print('Vanilla Neural Network best cross-validation accuracy:', nn_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the classifier using the best hyperparameters on the full training set\n",
    "# nn_clf = nn_grid_search.best_estimator_\n",
    "nn_clf = MLPClassifier(hidden_layer_sizes=(30,30), activation='relu', max_iter=500, random_state=42)\n",
    "nn_start_time = time.time()\n",
    "nn_clf.fit(X_train, y_train)\n",
    "nn_end_time = time.time()\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "nn_test_accuracy = nn_clf.score(X_test, y_test)\n",
    "print('Time required to train Vanilla Neural Network classifier:', nn_end_time - nn_start_time)\n",
    "print('Vanilla Neural Network test accuracy:', nn_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nn_grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the grid search\n",
    "nn_results = nn_grid_search.cv_results_\n",
    "\n",
    "nn_mean_scores = nn_results['mean_test_score']\n",
    "nn_mean_times = nn_results['mean_fit_time']\n",
    "nn_params = nn_results['param_activation']\n",
    "\n",
    "# Loop through each combination of hyperparameters\n",
    "for mean_score, mean_time, param in zip(nn_mean_scores, nn_mean_times, nn_params):\n",
    "    print(\"HiddenLayerSize: %r | %.2fs | test-score: %f\" % (param, mean_time, mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot the results of the grid search against the hyperparameter values \"\"\"\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(nn_params, nn_mean_scores, 'o:', label=\"Mean Score\", linestyle=':')\n",
    "ax2.plot(nn_params, nn_mean_times, 'o:', color='orange', label=\"Mean Fit Time\")\n",
    "ax1.set_xlabel('Activation function')\n",
    "ax1.set_ylabel('Score', color='blue')\n",
    "ax2.set_ylabel('Fit time [s]', color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVM classifier and train it on the training data\n",
    "svm_clf = SVC(kernel=\"rbf\",random_state=42)\n",
    "\n",
    "svm_param_grid = {\n",
    "    'kernel': ['linear','poly', 'sigmoid'],\n",
    "    'C': [10],\n",
    "    'random_state': [42],\n",
    "}\n",
    "\n",
    "svm_grid_search = RandomizedSearchCV(svm_clf, svm_param_grid, cv=5, scoring='accuracy', verbose=10, n_iter=10)\n",
    "\n",
    "svm_start_time = time.time()\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "print('SVM best hyperparameters:', svm_grid_search.best_params_)\n",
    "print('SVM best cross-validation accuracy:', svm_grid_search.best_score_)\n",
    "print('Time required to perform GridSearch on SVM classifier:', svm_end_time - svm_start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to train SVM classifier: 315.5798075199127\n",
      "SVM test accuracy: 0.9059316495598355\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel=\"rbf\", C=10, random_state=42)\n",
    "\n",
    "svm_start_time = time.time()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_end_time = time.time()\n",
    "\n",
    "svm_test_accuracy = svm_clf.score(X_test, y_test)\n",
    "print('Time required to train SVM classifier:', svm_end_time - svm_start_time)\n",
    "print('SVM test accuracy:', svm_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: 'linear' | 463.95s | test-score: 0.904653\n",
      "kernel: 'poly' | 274.41s | test-score: 0.832592\n",
      "kernel: 'sigmoid' | 393.91s | test-score: 0.728335\n"
     ]
    }
   ],
   "source": [
    "# Get the results of the grid search\n",
    "svm_results = svm_grid_search.cv_results_\n",
    "\n",
    "svm_mean_scores = svm_results['mean_test_score']\n",
    "svm_mean_score_times = svm_results['mean_score_time']\n",
    "svm_mean_fit_times = svm_results['mean_fit_time']\n",
    "svm_param = svm_results['param_kernel']\n",
    "\n",
    "for mean_score, mean_score_time, mean_fit_time, param in zip(svm_mean_scores, svm_mean_score_times, svm_mean_fit_times, svm_param):\n",
    "    print(\"kernel: %r | %.2fs | test-score: %f\" % (param, mean_fit_time, mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot the results of the grid search against the hyperparameter values \"\"\"\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(svm_param_C, svm_mean_scores,'o:', color='blue', label=\"Mean Score\")\n",
    "ax2.plot(svm_param_C, svm_mean_fit_times,'o:', color='orange', label=\"Mean Fit Time\")\n",
    "ax1.set_xlabel('Regularization parameter')\n",
    "ax1.set_ylabel('Score', color='blue')\n",
    "ax2.set_ylabel('Fit time', color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier and train it on the training data\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [10,15,20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=5, scoring='accuracy', verbose=10)\n",
    "\n",
    "rf_start_time = time.time()\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "print('RF best hyperparameters:', rf_grid_search.best_params_)\n",
    "print('RF best cross-validation accuracy:', rf_grid_search.best_score_)\n",
    "print('Time required to grid search for RF classifier:', rf_end_time - rf_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=50, max_depth=20, min_samples_split=5, random_state=42)\n",
    "\n",
    "rf_start_time = time.time()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_end_time = time.time()\n",
    "\n",
    "rf_test_accuracy = rf_clf.score(X_test, y_test)\n",
    "print('Time required to train RF classifier:', rf_end_time - rf_start_time)\n",
    "print('RF test accuracy:', rf_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the grid search\n",
    "rf_results = rf_grid_search.cv_results_\n",
    "\n",
    "rf_mean_scores = rf_results['mean_test_score']\n",
    "rf_mean_fit_times = rf_results['mean_fit_time']\n",
    "rf_param_min_samples_split  = rf_results['param_min_samples_split']\n",
    "rf_param_max_depth  = rf_results['param_max_depth']\n",
    "rf_param_n_estimators  = rf_results['param_n_estimators']\n",
    "\n",
    "for mean_score, mean_fit_time, n_est, min_sample, max_depth in zip(rf_mean_scores, rf_mean_fit_times, rf_param_n_estimators, rf_param_min_samples_split, rf_param_max_depth):\n",
    "    print(\"n_estimators: %r | min_samples_split: %r | max_depth: %r | %.2fs | test-score: %f\" % (n_est, min_sample, max_depth, mean_fit_time, mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\"\"\" plot the results of the grid search against the hyperparameter values \"\"\"\n",
    "fig = sns.scatterplot(x=rf_param_min_samples_split, y=rf_mean_scores, hue=rf_param_max_depth, size=rf_param_n_estimators)\n",
    "fig.set_xlabel('Min samples split')\n",
    "fig.set_ylabel('Score')\n",
    "fig.set_title('Random Forest Grid Search Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test set\n",
    "nn_predictions = nn_clf.predict(X_test)\n",
    "svm_predictions = svm_clf.predict(X_test)\n",
    "rf_predictions = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary that maps model names to their hyperparameters\n",
    "model_hyperparams = {\n",
    "    # 'Vanilla Neural Network': nn_grid_search.best_params_,\n",
    "    # 'SVM': svm_grid_search.best_params_,\n",
    "    # 'Random Forest': rf_grid_search.best_params_\n",
    "    'Vanilla Neural Network': {'hidden_layer_sizes': (30, 30), 'activation':'relu', 'max_iter': 500},\n",
    "    'SVM': {'C': 10, 'kernel': 'rbf'},\n",
    "    'Random Forest': {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 50}\n",
    "}\n",
    "\n",
    "# Compute the confusion matrix for each model\n",
    "nn_confusion_matrix = confusion_matrix(y_test, nn_predictions, labels=nn_clf.classes_)\n",
    "svm_confusion_matrix = confusion_matrix(y_test, svm_predictions, labels=svm_clf.classes_)\n",
    "rf_confusion_matrix = confusion_matrix(y_test, rf_predictions, labels=rf_clf.classes_)\n",
    "\n",
    "# Print the confusion matrix and hyperparameters for each model\n",
    "print('Vanilla Neural Network confusion matrix:')\n",
    "print(nn_confusion_matrix)\n",
    "print('Vanilla Neural Network hyperparameters:', model_hyperparams['Vanilla Neural Network'])\n",
    "\n",
    "print('SVM confusion matrix:')\n",
    "print(svm_confusion_matrix)\n",
    "print('SVM hyperparameters:', model_hyperparams['SVM'])\n",
    "\n",
    "print('Random Forest confusion matrix:')\n",
    "print(rf_confusion_matrix)\n",
    "print('Random Forest hyperparameters:', model_hyperparams['Random Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_disp_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix=nn_confusion_matrix, display_labels=nn_clf.classes_)\n",
    "svm_disp_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix=svm_confusion_matrix, display_labels=svm_clf.classes_)\n",
    "rf_disp_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix=rf_confusion_matrix, display_labels=rf_clf.classes_)\n",
    "\n",
    "nn_disp_confusion_matrix.plot()\n",
    "svm_disp_confusion_matrix.plot()\n",
    "rf_disp_confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of each classifier\n",
    "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Vanilla Neural Network Accuracy:\", nn_accuracy)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(nn_clf, 'nn_clf_2x30_relu.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(nn_grid_search, 'nn_grid_search.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(svm_clf, 'svm_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(svm_grid_search, 'svm_grid_search.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(rf_clf, 'rf_clf_n50_split5_depth20.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(rf_grid_search, 'rf_grid_search.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf = load('nn_clf_2x30_relu.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = load('svm_clf_rbf_c10.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = load('rf_clf_n50_split5_depth20.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215dff16a6ee4c530643a350677784407d2df1cb8e660c61af1350fdacb0e0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
